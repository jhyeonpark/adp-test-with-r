[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R을 활용한 데이터 분석 전문가(ADP) 준비하기",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\nkmeans_spec &lt;- linear_reg()\nshow_engines(\"linear_reg\")\n\n# A tibble: 7 × 2\n  engine mode      \n  &lt;chr&gt;  &lt;chr&gt;     \n1 lm     regression\n2 glm    regression\n3 glmnet regression\n4 stan   regression\n5 spark  regression\n6 keras  regression\n7 brulee regression\n\n\n\n1.0.0.1 모델 평가\n\nyardstick::metric_set()\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "section_previous_tests.html",
    "href": "section_previous_tests.html",
    "title": "ADP 실기시험: 기출문제",
    "section": "",
    "text": "R를 활용해 ADP 실기시험 기출문제를 다룸"
  },
  {
    "objectID": "test_27.html",
    "href": "test_27.html",
    "title": "2  제27회 ADP 실기 문제 풀이",
    "section": "",
    "text": "1. 데이터 전처리"
  },
  {
    "objectID": "test_27.html#데이터-탐색eda을-수행하라.",
    "href": "test_27.html#데이터-탐색eda을-수행하라.",
    "title": "2  제27회 ADP 실기 문제 풀이",
    "section": "1.1. 데이터 탐색(EDA)을 수행하라.",
    "text": "1.1. 데이터 탐색(EDA)을 수행하라.\n필요한 패지키를 설치하고 불러온다.\n\npacman::p_load(tidyverse, tidymodels, data.table, gt, \n               skimr, ggcorrplot, themis, solitude)\n\n데이터를 불러온다.\n\ndb_1a &lt;- fread(\"test/27/data/problem1.csv\")\n\n탐색적 자료분석(EDA)를 skim으로 수행한다.\n\ndb_1a %&gt;% skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n1193\n\n\nNumber of columns\n20\n\n\nKey\nNULL\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n20\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nTime\n0\n1\n91514.49\n47896.08\n60.00\n50265.00\n81797.00\n136995.00\n172676.00\n▃▇▅▅▇\n\n\nV1\n0\n1\n-0.76\n3.62\n-30.55\n-1.30\n-0.30\n1.25\n2.32\n▁▁▁▁▇\n\n\nV2\n0\n1\n0.54\n2.66\n-33.64\n-0.44\n0.23\n1.11\n19.17\n▁▁▁▇▁\n\n\nV3\n0\n1\n-1.15\n3.91\n-31.10\n-1.61\n-0.23\n0.81\n3.32\n▁▁▁▁▇\n\n\nV4\n0\n1\n0.78\n2.35\n-4.29\n-0.61\n0.33\n1.34\n12.11\n▂▇▂▁▁\n\n\nV5\n0\n1\n-0.41\n2.70\n-22.11\n-0.84\n-0.07\n0.68\n15.28\n▁▁▇▅▁\n\n\nV6\n0\n1\n-0.28\n1.51\n-10.89\n-1.02\n-0.38\n0.30\n6.27\n▁▁▆▇▁\n\n\nV7\n0\n1\n-0.85\n3.40\n-37.06\n-0.81\n-0.08\n0.46\n8.12\n▁▁▁▂▇\n\n\nV8\n0\n1\n0.15\n2.47\n-37.35\n-0.22\n0.07\n0.45\n20.01\n▁▁▁▇▁\n\n\nV9\n0\n1\n-0.45\n1.66\n-11.13\n-1.04\n-0.21\n0.45\n5.92\n▁▁▃▇▁\n\n\nV10\n0\n1\n-0.90\n2.90\n-23.23\n-0.88\n-0.23\n0.29\n7.14\n▁▁▁▇▁\n\n\nV11\n0\n1\n0.66\n1.96\n-2.65\n-0.60\n0.28\n1.21\n11.67\n▇▇▁▁▁\n\n\nV12\n0\n1\n-1.01\n3.00\n-17.23\n-0.97\n-0.01\n0.51\n3.11\n▁▁▁▂▇\n\n\nV13\n0\n1\n0.01\n1.01\n-2.80\n-0.69\n0.02\n0.70\n3.07\n▁▅▇▃▁\n\n\nV14\n0\n1\n-1.17\n3.23\n-18.49\n-0.95\n-0.10\n0.42\n3.89\n▁▁▁▂▇\n\n\nV15\n0\n1\n0.02\n0.91\n-4.50\n-0.55\n0.05\n0.66\n2.87\n▁▁▆▇▁\n\n\nV16\n0\n1\n-0.63\n2.27\n-14.13\n-0.70\n-0.06\n0.46\n3.14\n▁▁▁▃▇\n\n\nV17\n0\n1\n-1.07\n3.81\n-25.16\n-0.68\n-0.15\n0.37\n6.74\n▁▁▁▇▃\n\n\nAmount\n0\n1\n88.89\n220.14\n0.00\n3.54\n20.99\n77.49\n3335.73\n▇▁▁▁▁\n\n\nClass\n0\n1\n0.17\n0.37\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\n\n\n\n탐색한 결과는 다음과 같다:\n\n결측치는 존재하지 않음\n데이터는 모두 숫자형(numeric)으로 구성되었으나, Class는 데이터 분포 등으로 미루어보아 요인(factor)로 판단\nClass는 1인 경우가 16.7%로 불균형 라벨로 판단\n\n종속변수와 독립변수 관계를 시각화한다.\n\ndb_1a %&gt;% \n  # id 생성\n  mutate(id = row_number()) %&gt;%\n  # Wide-to-long 변환\n  pivot_longer(cols = !c(id, Class)) %&gt;%\n  ggplot(aes(x = as.factor(Class), y = value)) +\n  geom_boxplot() +\n  facet_wrap(name ~ ., scales = \"free\") +\n  labs(x = \"\", y = \"\") +\n  scale_y_continuous(labels = comma)"
  },
  {
    "objectID": "test_27.html#변수간-상관관계를-시각화하고-전처리가-필요함을-설명하라",
    "href": "test_27.html#변수간-상관관계를-시각화하고-전처리가-필요함을-설명하라",
    "title": "2  제27회 ADP 실기 문제 풀이",
    "section": "1.2. 변수간 상관관계를 시각화하고 전처리가 필요함을 설명하라",
    "text": "1.2. 변수간 상관관계를 시각화하고 전처리가 필요함을 설명하라\n상관관계를 시각화한다.\n\ndb_1a %&gt;% select(-c(\"Time\", \"Class\")) %&gt;%\n  cor() %&gt;% ggcorrplot(type = \"lower\", lab = TRUE, lab_size = 2)\n\n\n\n\nV1-V3, V14-V17 등 상관계수가 0.75보다 큰 관계가 보인다. 이를 활용하여 종속변수를 측정하면 다중공선성 문제가 발생하여 정확한 독립변수 관계를 측정하기 어렵다."
  },
  {
    "objectID": "test_27.html#차원축소-방법-2가지-이상을-비교하고-한-가지를-선택하라.",
    "href": "test_27.html#차원축소-방법-2가지-이상을-비교하고-한-가지를-선택하라.",
    "title": "2  제27회 ADP 실기 문제 풀이",
    "section": "2.1. 차원축소 방법 2가지 이상을 비교하고 한 가지를 선택하라.",
    "text": "2.1. 차원축소 방법 2가지 이상을 비교하고 한 가지를 선택하라.\n차원축소 방법에는 PCA 주성분분석과, MDS 다차원 척도법, t-SNE가 있다. 주성분 분석은 데이터 분산을 최대한 보존하면서 차원을 축소하여 정보 손실이 적고 계산 비용이 낮다는 장점이 있지만, 선형 관계에 의존하여 비선형 구조가 잘 표현되기 어렵고 이상치에 민감하게 작동한다. 다차원 척도법은 데이터 샘플 거리를 보존하여 축소하는 방법으로 비선형 구조에도 잘 작동하게 거리 정보를 유지하지만, 계산 비용이 높고 데이터 크기에 민감하다. 마지막으로 t-SEN은 비선형 차원 축소로 시각화에 효과적이지만 하이퍼파라미터에 민감할 수 있다.\n여기서는 가장 기본적이면서 데이터 손실을 줄이는 PCA 주성분분석을 활용한다.\nPCA에 필요한 파라미터인 주성분 개수는 아래 scree 그래프로 파악한다.\n\ndb_1b &lt;- db_1a %&gt;% select(-c(\"Time\", \"Class\"))\n\n# PCA를 위한 recipe 생성\nrec &lt;- recipe(~., data = db_1b) %&gt;%\n  step_center(all_predictors()) %&gt;%\n  step_scale(all_predictors()) %&gt;%\n  step_pca(all_predictors())\n\n# recipe 준비 (학습)\nprep_rec &lt;- prep(rec)\n\n# Scree 그래프\nsdev &lt;- prep_rec$steps[[3]]$res$sdev\npercent_variation &lt;- sdev^2 / sum(sdev^2)\ndata.frame(PC=paste0(\"PC\",1:length(sdev)),\n                     var_explained=percent_variation,\n                     stringsAsFactors = FALSE) %&gt;%\n  mutate(PC = fct_inorder(PC)) %&gt;%\n  ggplot(aes(x=PC,y=var_explained))+geom_col()\n\n\n\n\n2개 이상이 되면 주성분이 1개 더 생긴다고 크게 설명되지 않은 분산이 커지지 않는다. 따라서 주성분은 2개로 가정한다.\n2개로 설정한 PCA 결과를 시각화하면 다음과 같다.\n\ndb_1b &lt;- db_1a %&gt;% select(-c(\"Time\", \"Class\"))\n# PCA를 위한 recipe 생성\nrec &lt;- recipe(~., data = db_1b) %&gt;%\n  step_center(all_predictors()) %&gt;%\n  step_scale(all_predictors()) %&gt;%\n  step_pca(all_predictors(), num_comp = 2) # 주성분 2개로 한정\n\nprep_rec &lt;- prep(rec)\n\ntidy_rec &lt;- tidy(prep_rec, number = 3)\n\ntidy_rec %&gt;%\n  filter(component %in% paste0(\"PC\", 1:2)) %&gt;%\n  mutate(component = fct_inorder(component)) %&gt;%\n  ggplot(aes(value, terms, fill = terms)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~component, nrow = 1) +\n  labs(y = NULL, x = NULL) +\n  theme_bw()"
  },
  {
    "objectID": "test_27.html#각-샘플링의-장점과-단점을-설명하고-한-가지를-추천하라.",
    "href": "test_27.html#각-샘플링의-장점과-단점을-설명하고-한-가지를-추천하라.",
    "title": "2  제27회 ADP 실기 문제 풀이",
    "section": "3.1. 각 샘플링의 장점과 단점을 설명하고 한 가지를 추천하라.",
    "text": "3.1. 각 샘플링의 장점과 단점을 설명하고 한 가지를 추천하라.\n오버샘플링은 소수 클래스의 샘플 수를 늘려 전체 데이터셋의 균형을 맞추는 방법이다.\n\n장점: 소수 클래스 정보를 모두 활용할 수 있어, 정보 손실이 없음\n단점: 샘플이 과화게 증가하면 모델 과적합 위험\n\n언더샘플링은 다수 클래스의 샘플 수를 줄여서 전체 데이터셋의 균형을 맞추는 방법이다.\n\n장점: 다수 샘플이 과하게 많을 경우, 이를 줄여 모델 과적합 방지\n단점: 샘플 줄이는 과정에서 중요한 정보를 잃을 수 있음\n\n해당 데이터셋에는 오버샘플링을 적용한 것을 추천한다. Class의 소수 클래스의 개수가 20개로, 언더샘플링을 사용할 시 다수 샘플의 정보를 과도하게 잃기 때문이다.\n\ntable(db_1a$Class)\n\n\n  0   1 \n993 200"
  },
  {
    "objectID": "test_27.html#알고리즘-2가지-이상을-비교하고-성능을-측정하라.",
    "href": "test_27.html#알고리즘-2가지-이상을-비교하고-성능을-측정하라.",
    "title": "2  제27회 ADP 실기 문제 풀이",
    "section": "3.2. 알고리즘 2가지 이상을 비교하고 성능을 측정하라.",
    "text": "3.2. 알고리즘 2가지 이상을 비교하고 성능을 측정하라.\n두 오버샘플링 알고리즘, 1) SMOTE과 2) upsampling를 사용한다.\n\ndb_1c &lt;- db_1a[, -c(\"Time\")]\n\n# Recipe 만들기\nrec &lt;- recipe(Class ~ ., data = db_1c) %&gt;%\n  step_mutate(Class = as.factor(Class)) %&gt;%\n  step_center(all_predictors(),  -all_outcomes()) %&gt;%\n  step_scale(all_predictors(),  -all_outcomes()) %&gt;%\n  step_pca(all_predictors(),  -all_outcomes(), num_comp = 2) # 주성분 2개로 한정\n\n# 모델 정의\nmodel_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n# SMOTE\nrec_smote &lt;- rec %&gt;% step_smote(Class) %&gt;% prep(db_1c) %&gt;% bake(new_data = NULL)\nrec_upsample &lt;- rec %&gt;% step_upsample(Class) %&gt;% prep(db_1c) %&gt;% bake(new_data = NULL)\n\nbind_rows(rec_smote %&gt;% mutate(model = \"smote\"),\n          rec_upsample %&gt;% mutate(model = \"upsample\")) %&gt;%\n  ggplot(aes(x = PC1, y = PC2, color = model)) +\n  geom_point(alpha = 0.8) +\n  theme_bw()\n\n\n\n\n위 그래프에서 보이듯, 단순히 소수 샘플을 늘린 upsample 알고리즘에 비해 SMOTE 알고리즘이 더 다양한 차원 정보를 포함하고 있어 더 좋은 성능을 보인다고 할 수 있다."
  },
  {
    "objectID": "test_27.html#현재까지-전처리한-데이터를-통해-모델-수행-후-결과를-분석",
    "href": "test_27.html#현재까지-전처리한-데이터를-통해-모델-수행-후-결과를-분석",
    "title": "2  제27회 ADP 실기 문제 풀이",
    "section": "3.3. 현재까지 전처리한 데이터를 통해 모델 수행 후, 결과를 분석",
    "text": "3.3. 현재까지 전처리한 데이터를 통해 모델 수행 후, 결과를 분석\n\nset.seed(2023)\n\ndb_1c &lt;- db_1a[, -c(\"Time\")]\n\n# Recipe 만들기\nrec &lt;- recipe(Class ~ ., data = db_1c) %&gt;%\n  step_mutate(Class = as.factor(Class)) %&gt;%\n  step_center(all_predictors(),  -all_outcomes()) %&gt;%\n  step_scale(all_predictors(),  -all_outcomes()) %&gt;%\n  step_pca(all_predictors(),  -all_outcomes(), num_comp = 2) # 주성분 2개로 한정\n\n# 모델 정의\nmodel_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n# SMOTE\nrec_smote &lt;- rec %&gt;% step_smote(Class) %&gt;% prep(db_1c)\nwk_smote &lt;- workflow() %&gt;% add_recipe(rec_smote) %&gt;% add_model(model_spec)\n\ncv &lt;- vfold_cv(db_1c)\n\nresult_smote &lt;- fit_resamples(\n  wk_smote, \n  resamples = cv, \n  control = control_resamples(save_pred = TRUE))\n\npredictions &lt;- result_smote %&gt;% \n  collect_predictions()\n\ncollect_metrics(result_smote)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.960    10 0.00671 Preprocessor1_Model1\n2 roc_auc  binary     0.922    10 0.0185  Preprocessor1_Model1\n\npredictions %&gt;% \n  yardstick::roc_curve(Class, .pred_0) %&gt;% autoplot()\n\n\n\n\n분석 결과, 정확도는 95.9%, AUC는 92.1%로 분류 성능을 보인다."
  },
  {
    "objectID": "test_27.html#이상탐지-모델-2가지-이상을-기술하고-장점과-단점을-설명해라.",
    "href": "test_27.html#이상탐지-모델-2가지-이상을-기술하고-장점과-단점을-설명해라.",
    "title": "2  제27회 ADP 실기 문제 풀이",
    "section": "2.1 4.1. 이상탐지 모델 2가지 이상을 기술하고 장점과 단점을 설명해라.",
    "text": "2.1 4.1. 이상탐지 모델 2가지 이상을 기술하고 장점과 단점을 설명해라.\n\nIsolation Forest: 데이터 분포를 가정하지 않고 작동하며, 이상값과 정상값을 분리하는 데 필요한 경로 길이를 기반으로 이상 점수를 계산합니다. 이상값은 일반적으로 더 짧은 경로로 분리될 수 있으므로, 이상 점수가 높을수록 해당 데이터 포인트는 이상값일 가능성이 높음\n\n장점: 대용량 데이터에 효과적이며, 별도의 정규화 과정이 필요 없음\n단점: 어떻게 이상치를 분리했는지 파악이 어려워 데이터 해석이 힘듦\n\nAutoencoder: 비지도 학습의 일종으로, 원본 입력을 재구성하는 방식으로 작동함. 이상 탐지에서는, 정상 데이터를 사용하여 Autoencoder를 훈련시키고, 이를 사용하여 입력 데이터를 재구성, 이상한 데이터는 재구성 오차가 크게 나타남. 이 재구성 오차를 임계값과 비교하여 데이터 포인트가 이상인지 판별함.\n\n장점: 비선형성 패턴을 인코딩하고 특성 선택 과정이 필요 없음\n단점: 네트워크 아키텍처에 의존하므로 복잡함"
  },
  {
    "objectID": "test_27.html#모델-구현하고-3에서-만든-모델과-비교",
    "href": "test_27.html#모델-구현하고-3에서-만든-모델과-비교",
    "title": "2  제27회 ADP 실기 문제 풀이",
    "section": "2.2 4.2. 모델 구현하고 3에서 만든 모델과 비교",
    "text": "2.2 4.2. 모델 구현하고 3에서 만든 모델과 비교\n\ndb_1c &lt;- db_1a[, -c(\"Time\")]\n\n# Recipe 만들기\nrec &lt;- recipe(Class ~ ., data = db_1c) %&gt;%\n  step_mutate(Class = as.factor(Class)) %&gt;%\n  step_center(all_predictors(),  -all_outcomes()) %&gt;%\n  step_scale(all_predictors(),  -all_outcomes()) %&gt;%\n  step_pca(all_predictors(),  -all_outcomes(), num_comp = 2) # 주성분 2개로 한정\n\n# SMOTE\nrec_smote &lt;- rec %&gt;% step_smote(Class) %&gt;% prep(db_1c)\n\n\n\nwk_smote &lt;- workflow() %&gt;% add_recipe(rec_smote) %&gt;% add_model(model_spec)\n\ndata_preprocessed &lt;- juice(rec_smote)\n\nmodel &lt;- isolationForest$new()\nmodel$fit(data_preprocessed[, -which(names(data_preprocessed) == \"Class\")])\n\nINFO  [21:54:06.467] dataset has duplicated rows\nINFO  [21:54:06.484] Building Isolation Forest ...\nINFO  [21:54:06.523] done\nINFO  [21:54:06.523] Computing depth of terminal nodes ...\nINFO  [21:54:06.720] done\nINFO  [21:54:06.758] Completed growing isolation forest\n\nscores &lt;- model$predict(data_preprocessed[, -which(names(data_preprocessed) == \"Class\")])\ndata_preprocessed$anomaly_score &lt;- scores\n\nquantile(data_preprocessed$anomaly_score$anomaly_score)\n\n       0%       25%       50%       75%      100% \n0.5820092 0.5827973 0.5847722 0.5955529 0.7654805 \n\n# 이상치 점수를 기반으로 이상치 판단\nthreshold &lt;- 0.6\ndata_preprocessed$anomaly &lt;- ifelse(data_preprocessed$anomaly_score &gt; threshold, 1, 0)\n\n# SMOTE 후에 모델 훈련 및 성능 측정\nttt &lt;- as.data.table(data_preprocessed$anomaly)\n\ndata_preprocessed$anomaly &lt;- as.factor(ttt$anomaly_score)\ntable(data_preprocessed$Class, data_preprocessed$anomaly)\n\n   \n      0   1\n  0 929  64\n  1 649 344\n\ntttt &lt;- data_preprocessed %&gt;% \n  conf_mat(truth = Class, estimate = anomaly) \n\n\nclass_metrics &lt;- metric_set(accuracy, sens, spec)\n\ndata_preprocessed |&gt;\n  class_metrics(truth = Class, estimate = anomaly)\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.641\n2 sens     binary         0.936\n3 spec     binary         0.346"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]